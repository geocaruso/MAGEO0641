# Continuous distributions

In addition to the normal and uniform distributions, a number of other continuous distributions are often used, corresponding to different assumptions about the processes that shape the population.

## Exponential

A random variable $X \in [0;+\infty[$ following an exponential distribution with parameter $\lambda > 0$ can be expressed as: $X \sim \epsilon(\lambda)$ with expectation $E(X) = 1/ \lambda$ and variance $Var(X) = 1/ \lambda^2$.

Its **density function** can be written as:

$$f(x) = λ {e}^{- λ x} \text{ for } x \geq 0$$ $$f(x) = 0 \text{ for } x < 0$$

Its **cumulative distribution function** is defined by:

$$F_X(x) = 1 - \exp{(- \lambda x)} \text{ for } x \geq 0$$ $$F_X(x) = 0 \text{ for } x < 0$$

```{r exp}
x <- seq(0,8,0.01)
dExp.5 <- dexp(x, .5)
dExp1 <- dexp(x, 1)
dExp2 <- dexp(x, 2)
dExp3 <- dexp(x, 3)
```

```{r expDensity}
plot(x, dExp3, type = 'l', col = 'green',
     main = 'Density function of X~Exp(lambda)', ylab = 'f(x)')
lines(x, dExp2, col = 'gold')
lines(x, dExp1, col = 'darkorange')
lines(x, dExp.5, col = 2)
legend("topright", lty = 1,
       legend = c("lambda = 0.5", "lambda = 1", 
                  "lambda = 2", "lambda = 3"),
       col = c(2, 'darkorange', 'gold', 'green'))
```

```{r expCDF}
plot(x, pexp(x, 3), type = 'l', col = 'green',
     main = 'Cumulative Distribution Function of X~Exp(lambda)', ylab = 'F(x)')
lines(x, pexp(x, 2), col='gold')
lines(x, pexp(x, 1), col='darkorange')
lines(x, pexp(x, .5), col=2)
legend("bottomright", lty = 1,
       legend = c("lambda = 0.5", "lambda = 1", "lambda = 2", "lambda = 3"),
       col = c(2, 'darkorange', 'gold', 'green'))
```

## Chi-square

A random variable $X$ following a chi-square (or khi-square) distribution can be expressed as: $X \sim \chi^2(k)$ with parameter $k> 0$, expectation $E(X) = k$, variance $Var(X) = 2k$.

$k$ represents the degree of freedom.

The **density function** is

$$f_X(x) = \dfrac {1} {2^{k/2} \gamma(k/2)} x^{(k/2)-1} \exp{(\dfrac{-x}{2})} \text{ for } x \geq 0$$

$$f_X(x) = 0 \text{ for } x < 0$$

```{r chi2}
x <- seq(0,8,0.01)
dChiSq1 <- dchisq(x, df=1)
dChiSq2 <- dchisq(x, df=2)
dChiSq3 <- dchisq(x, df=3)
dChiSq6 <- dchisq(x, df=6)
```

We see (and know from the CLT) that when the degrees of freedom increases, the function gets closer to a normal distribution. However it is not symmetrical and the right hand side stays longer than in the normal distribution for quite some time.

```{r chi2Density}
plot(x, dChiSq1, type = 'l', col = 2, ylim = c(0, 1.25),
     main = 'Density function of X~Chi^2(p)', ylab = 'f(x)')
lines(x, dChiSq2, col = 'darkorange')
lines(x, dChiSq3, col = 'gold')
lines(x, dChiSq6, col = 'green')
legend("topright", lty = 1,
       legend = c("k = 1", "k = 2", "k = 3", "k = 6"),
       col = c(2, 'darkorange', 'gold', 'green'))
```

The cumulative density is as follows:

```{r chi2CDF}
plot(x, pchisq(x, df=1), type = 'l', col = 2,
     main = 'Cumulative Distribution Function of X~Chi2(p)', ylab = 'F(x)')
lines(x, pchisq(x, df=2), col='darkorange')
lines(x, pchisq(x, df=3), col='gold')
lines(x, pchisq(x, df=6), col='green')
legend("bottomright", lty = 1,
       legend = c("k = 1", "k = 2", "k = 3", "k = 6"),
       col = c(2, 'darkorange', 'gold', 'green'))
```

The chi-square distribution is typically used to test the independence of two variables. It is typically applied to a categorical or ordinal metric along two categories, e.g. the level of education of Luxembourg natives vs Luxembourg migrants or the counts of votes for Kamala Harris among young vs elders population or among urban vs rural population. It is thus often applied to contingency tables after the cross-tabulation of two factors in order to test if observed frequencies differ from expected frequencies.

The df considered are usually low since it corresponds to the number of categories-1 (e.g. urban+rural, i.e. 2 -1=1) times the types of output -1, (e.g. vote for Harris vs Trump, i.e. 2-1=1). Thus far from a normal distribution.

## Student t-distribution

A random variable $X$ following a student distribution, can be expressed as: $X \sim t(n)$ with parameter $n$ degrees of freedom.

Its **density function** is

$$f(x) = \dfrac{1}{\sqrt{n\pi}} \dfrac {\gamma{(\dfrac{n+1}{2})}} {\gamma{(\dfrac{n}{2})}} \dfrac {1} {(1+\dfrac{x^2}{n})^{(n+1)/2}} \text{ for all } x\in R$$ We have: $$E(X) = 0 \text{ for } n \ge 2$$ $$Var(X) = \dfrac{n}{n-2} \text{ for } n \ge 3$$

If we have a random variable $U \sim N (0, 1)$ and a random variable $X \sim \chi^2(n)$ which are independent, then the random variable $T_n = \dfrac{U}{\sqrt{X/n}}$ follows a student distribution $t(n)$

```{r student}
x <- seq(-8, 8, 0.01)
dStudent1 <- dt(x, 1)
dStudent2 <- dt(x, 2)
dStudent4 <- dt(x, 4)
```

```{r studentDensity}
plot(x, dnorm(x), type = 'l', col = 'darkgray', xlim = c(-4, 4), lty = 3,
     main = 'Density function of X~t(n)', ylab = 'f(x)')
lines(x, dStudent4, col = 'gold')
lines(x, dStudent2, col = 'darkorange')
lines(x, dStudent1, col = 2)
legend("topright", lty = c(rep(1, 3), 3),
       legend = c("t(n = 1)", "t(n = 2)", "t(n = 4)", "N(0,1)"),
       col = c(2, 'darkorange', 'gold', 'darkgray'))
```

```{r studentCDF}
plot(x, pnorm(x), type = 'l', col = 'darkgray', lty = 3,
     main = 'Cumulative Distribution Function of X~t(n)', ylab = 'F(x)')
lines(x, pt(x, 2), col='gold')
lines(x, pt(x, 3), col='darkorange')
lines(x, pt(x, 6), col=2)
legend("bottomright", lty = c(rep(1, 3), 3),
       legend = c("t(n = 1)", "t(n = 2)", "t(n = 4)", "N(0,1)"),
       col = c(2, 'darkorange', 'gold', 'darkgray'))
```

Compared to the normal distribution, we can see the t-distribution depends solely on $n$. It is used for continuous variables in the non-rare cases where the sample size is small and the variance of the population is unknown.

t-Student's tests are typically used to test whether two samples have different means or if a sample mean differ from a given value.

## Fisher-Snedecor

A random variable $X$ following a Fisher-Snedecor distribution can be expressed as $X \sim F(n, p)$ with parameters $n$ and $p$ degrees of freedom.

Its **density function** is

$$f_X(x) = \dfrac {\gamma(\dfrac{n+p}{2})} {\gamma(\dfrac{n}{2}) \gamma(\dfrac{p}{2})} (\dfrac{n}{p})^{(n/2)} \dfrac{x^{\dfrac{n-2}{2}}}{(1 + \dfrac{n}{p}x)^{\dfrac{n-2}{2}}} \text{ for } x \geq 0$$ $$f_X(x) = 0 \text{ for } x < 0$$

We have:

$$E(X) = \dfrac{p}{p-2} \text{ for } p \ge 3$$ $$Var(X) = \dfrac{2p^2(n+p-2)}{n(p-2)^2(p-4)} \text{ for } p \ge 5$$

If we have two random variables $X$ and $Y$ independent such that $X \sim \chi^2(n)$ and $Y \sim \chi^2(p)$, then the random variable $\dfrac{X/n}{Y/p}$ follows a Fisher distribution $F(n, p)$

```{r fisher}
x <- seq(0, 3, 0.01)
dF1 <- df(x, 1, 1)
dF10 <- df(x, 10, 10)
dF20 <- df(x, 20, 20)
dF50 <- df(x, 50, 50)
```

```{r fisherDensity}
plot(x, dF1, type = 'l', col = 2, 
     main = 'Density function of X ~ F(n, p)', ylab = 'f(x)')
lines(x, dF10, col = 'darkorange')
lines(x, dF20, col = 'gold')
lines(x, dF50, col = 'green')
legend("topright", lty = 1,
       legend = c("F(n = p = 1)", "F(n = p = 10)", "F(n = p = 20)", "F(n = p = 50)"),
       col = c(2, 'darkorange', 'gold', 'green'))
```

```{r fisherCDF}
plot(x, pf(x, 50, 50), type = 'l', col = 'green',
     main = 'Cumulative Distribution Function of X ~ F(n, p)', ylab = 'F(x)')
lines(x, pf(x, 20, 20), col='gold')
lines(x, pf(x, 10, 10), col='darkorange')
lines(x, pf(x, 1, 1), col=2)
legend("bottomright", lty = 1,
       legend = c("F(n = p = 1)", "F(n = p = 10)", "F(n = p = 20)", "F(n = p = 50)"),
       col = c(2, 'darkorange', 'gold', 'green'))
```

You will mostly encounter F-tests in association with the goodness of fit of a regression analysis. It is used to test whether a linear model better fits the data than a 'intercept only' model, i.e. one that contains no independent variables, i.e. whether your model provides any useful information for prediction.
